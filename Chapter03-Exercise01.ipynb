{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/HDAT9500Banner.PNG)\n",
    "<br>\n",
    "\n",
    "# Chapter 3: Model Evaluation and Improvement\n",
    "# Exercise 1: Cross-Validation\n",
    "\n",
    "\n",
    "# 1. Introduction\n",
    "\n",
    "\n",
    "\n",
    "## 1.1. Aims of the Exercise:\n",
    " 1. To become familiar with cross-validation <font color=green>**(Step 5 of the ML work-flow)**</font>\n",
    "\n",
    "Useful readings:\n",
    "1. A gentle introduction to k-fold cross-validation: https://machinelearningmastery.com/k-fold-cross-validation/\n",
    "2. How to train a final machine learning model: https://machinelearningmastery.com/train-final-machine-learning-model/\n",
    "\n",
    "It aligns with all of the learning outcomes of our course: \n",
    "\n",
    "1.\tDistinguish a range of task specific machine learning techniques appropriate for Health Data Science.\n",
    "2.\tDesign machine learning tasks for Health Data Science scenarios.\n",
    "3.\tConstruct appropriate training and test sets for health research data.\n",
    "\n",
    "**NB Nomeclature: **\n",
    "Training, Validation and Test Set. \n",
    "\n",
    "* The training set, used to train the model\n",
    "* The validation set, used to evaluate model performance and adjust model parameters accordingly (for example, the alpha for Ridge Regression). Therefore, the validation set is used as an intermediate step. \n",
    "* The test set, used for final model evaluation. Book 2 uses \"the term validation set\" for what we call \"test set\" in Book 1.\n",
    "\n",
    "\n",
    "## 1.2. Jupyter Notebook Intructions\n",
    "1. Read the content of each cell.\n",
    "2. Where necessary, follow the instructions that are written in each cell.\n",
    "3. Run/Execute all the cells that contain Python code sequentially (one at a time), using the \"Run\" button.\n",
    "4. For those cells in which you are asked to write some code, please write the Python code first and then execute/run the cell.\n",
    " \n",
    "## 1.3. Tips\n",
    " 1. The square brackets on the left hand side of each cell indicate whether the cell has been executed or not. Empty square brackets mean that the cell has not been executed, whereas square brackets that contain a number means that the cell has been executed. Run all of the cells in sequence, using the \"Run\" button.\n",
    " 2. To edit this notebook, just double-click in each cell. In the document, each cell can be a \"Code\" cell or \"text-Markdown\" cell. To choose between these two options, go to the combo-box above. \n",
    " 3. If you want to save your notebook, please make sure you press the \"floppy disk\" icon button above. \n",
    " 4. To clean the content of all cells and re-start Notebook, please go to Cell->All Output->Clear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/ML-work-flow.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploration of the Wisconsin Cancer Data Set\n",
    "\n",
    "For data dictionary and all information:\n",
    "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">**Start Activity**</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Question 1:  Can you briefly describe the dataset in 10 lines? What are we trying to predict, that is, what is the research question (step 0 of our machine learning work-flow?)  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Write your answer here:</b>\n",
    "#####################################################################################################################\n",
    "\n",
    "(Double-click here)\n",
    "\n",
    "...\n",
    "#####################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">**End Activity**</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tumour images look like this (source: ftp://ftp.cs.wisc.edu/math-prog/cpo-dataset/machine-learn/cancer/cancer_images/):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/image1.gif)\n",
    "![alt text](images/image2.gif)\n",
    "![alt text](images/image3.gif)\n",
    "![alt text](images/image4.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('data/breast-cancer-wisconsin-data/data.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Preparing Data (step 2): Visualization and Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check:\n",
    "display(dataframe[:][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataframe.drop(axis=1, columns=['id', 'diagnosis'])\n",
    "y = dataframe['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "display(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "display (y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the visualization part, we are going to use two libraries: matplotlib and seaborn. This is in addition to the one that we have already learnt, plotnine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get going to visualise all the features. \n",
    "We start visualizing the first 5 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.plotting.scatter_matrix.html\n",
    "sm=pd.plotting.scatter_matrix(X.iloc[:, 0:5], c=dataframe.diagnosis, alpha=1, figsize=(22,22));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change the font sizes for name labels and axes ticks. In addition, we rotate the labels 90 degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.plotting.scatter_matrix.html\n",
    "\n",
    "sm=pd.plotting.scatter_matrix(X.iloc[:, 0:5], c=dataframe.diagnosis, alpha=1, figsize=(22,22));\n",
    "\n",
    "# Change labels and tickslabels sizes: \n",
    "# help: https://matplotlib.org/api/text_api.html#matplotlib.text.Text\n",
    "\n",
    "#y ticklabels\n",
    "a=[plt.setp(item.yaxis.get_majorticklabels(), 'size', 10) for item in sm.ravel()]\n",
    "#x ticklabels\n",
    "b=[plt.setp(item.xaxis.get_majorticklabels(), 'size', 10) for item in sm.ravel()]\n",
    "#y labels\n",
    "c=[plt.setp(item.yaxis.get_label(), 'size', 20) for item in sm.ravel()]\n",
    "#x labels\n",
    "d=[plt.setp(item.xaxis.get_label(), 'size', 20) for item in sm.ravel()]\n",
    "\n",
    "for ax in plt.gcf().axes:\n",
    "    plt.sca(ax)\n",
    "    plt.xlabel(ax.get_xlabel(), rotation=90)\n",
    "    plt.ylabel(ax.get_ylabel(), rotation=0, horizontalalignment='right')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the whole dataset (30 columns) - it will take a little while:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.plotting.scatter_matrix.html\n",
    "sm=pd.plotting.scatter_matrix(X.iloc[:, 0:31], c=dataframe.diagnosis, alpha=1, figsize=(22,22));\n",
    "\n",
    "# Change labels and tickslabels sizes: \n",
    "# help: https://matplotlib.org/api/text_api.html#matplotlib.text.Text\n",
    "#y ticklabels\n",
    "a=[plt.setp(item.yaxis.get_majorticklabels(), 'size', 10) for item in sm.ravel()]\n",
    "#x ticklabels\n",
    "b=[plt.setp(item.xaxis.get_majorticklabels(), 'size', 10) for item in sm.ravel()]\n",
    "#y labels\n",
    "c=[plt.setp(item.yaxis.get_label(), 'size', 20) for item in sm.ravel()]\n",
    "#x labels\n",
    "d=[plt.setp(item.xaxis.get_label(), 'size', 20) for item in sm.ravel()]\n",
    "\n",
    "for ax in plt.gcf().axes:\n",
    "    plt.sca(ax)\n",
    "    plt.xlabel(ax.get_xlabel(), rotation=90)\n",
    "    plt.ylabel(ax.get_ylabel(), rotation=0, horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation between continous features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "f,ax = plt.subplots(figsize=(20, 20))\n",
    "sns.heatmap(X.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">**Start Activity**</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Question 2:  Can you give an example of two features that are highly correlated and two features that are not correlated?  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Write your answer here:</b>\n",
    "#####################################################################################################################\n",
    "\n",
    "(Double-click here)\n",
    "\n",
    "...\n",
    "#####################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">**End Activity**</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://seaborn.pydata.org/generated/seaborn.countplot.html\n",
    "# https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Python_Seaborn_Cheat_Sheet.pdf\n",
    "ax = sns.countplot(y,label=\"Count\")       # M = 212, B = 357\n",
    "B, M = y.value_counts()\n",
    "print('Number of Benign: ',B)\n",
    "print('Number of Malignant : ',M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is not as imbalanced as the \"diabetes\" dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first ten features\n",
    "\n",
    "data = pd.concat([y,X.iloc[:, 0:9]],axis=1)\n",
    "data = pd.melt(data,id_vars=\"diagnosis\", var_name=\"features\", value_name='value')\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.violinplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data=data,split=True, inner=\"quart\")\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">**Start Activity**</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Question 3:  Check the previous plot. We can see clearly why we have to standardize features, or more generally scale features. Can you explain why?  </font>\n",
    "\n",
    "\n",
    "<p><font color='green'> Tip: I really enjoyed reading the Wikipedia entry, in case you want to know a bit more about feature scaling in general:\n",
    "https://en.wikipedia.org/wiki/Feature_scaling</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Write your answer here:</b>\n",
    "#####################################################################################################################\n",
    "\n",
    "(Double-click here)\n",
    "\n",
    "...\n",
    "#####################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">**End Activity**</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Preparing Data (step 2):  Standardization (Scaling of the Features) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to standardize the features in order to see how they look with the same scale. **We are not going to use the standardize features just yet for anything but <font color=green>visualization.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "\n",
    "#The standard score of a sample x is calculated as:\n",
    "#z = (x - u) / s\n",
    "#where u is the mean of the training samples, and s is the standard deviation of the training samples.\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "\n",
    "scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we have to apply the StandardScaler() to the training set ONLY. Nevertheless, this is just for visual purposes, so we are going to apply it to the whole data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale the training data, or the whole data in this case. Just for visual purposes\n",
    "scaler.fit(X)\n",
    "X_scaled_temp = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrame from X_scaled_temp array that contains the column names of the original dataset\n",
    "X_scaled=pd.DataFrame(X_scaled_temp, columns = list(X.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "X_scaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first ten features\n",
    "import seaborn as sns\n",
    "data = pd.concat([y,X_scaled.iloc[:, 0:9]],axis=1)\n",
    "data = pd.melt(data,id_vars=\"diagnosis\", var_name=\"features\", value_name='value')\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.violinplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data=data,split=True, inner=\"quart\")\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, all the features are at the same scale now and it will be easier for the ML algorithm to fit a model to predict the correct outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not going to scale the features just yet because the process is a bit more complicated in the case of applying cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Cross-Validation\n",
    "To this point, we have restrained ourselves to using the training-test approach for <b>model performance evaluation</b>. As you are aware, the training-test approach involves partitioning the data into two sets, one for training and one for testing. The advantage of the training-test approach is that it is simple to understand and implement. However, estimates of test error can be highly variable, with dependence on which records are selected for training and testing.\n",
    "\n",
    "\n",
    "Here, we will introduce to you another related **method of model performance evaluation** known as \"k-fold cross-validation\". In k-fold cross-validation, the original sample is randomly partitioned into k equal size subsamples, called **folds**. Of the k folds, a single fold is designated as the test set, and the remaining k-1 folds are used as training data. Now, here is where the method differs from the training-test approach. Previously, we would train a single model on a \"training fold\", evaluate on the \"test fold\", and then finish. Instead, now we train k models, each with a different test fold, and then average the performance to yield our final accuracy. It is common to choose k as either 5 or 10.<p>\n",
    "    \n",
    "To illustrate, consider the case of 5-fold cross-validation. Here, we split the data into 5 equally sized folds. Let's call them fold_1, fold_2, fold_3, fold_4, and fold_5. Then, choose one of the folds as the first test fold, and the remaining 4 folds are the training folds. Let's say we choose fold_1 for the first test fold, so we have fold_2, fold_3, fold_4, and fold_5 for training. Now, train and evaluate the first model using these folds. Let's call this model and its results model_1.<p> Now, we swap the test fold of fold_1 with a training fold that has not previously been used for testing. Let's say we swap fold_1 with fold_2. This means we have fold_2 as our new test fold, and we have fold_1, fold_3, fold_4, and fold_5 for training. Now, train and evaluate the second model and call it model_2.<p>\n",
    "\n",
    "Repeat this process until we have used all 5 of our folds for testing exactly once. We would now have 5 models and their associated performance evaluation results (either F1 score, accuracy,...), model_1, model_2, model_3, model_4, and model_5. We then average these results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Cross-Validation: standard logistic regression\n",
    "\n",
    "Here we will demonstrate k-fold cross-validation for our data, to evaluate the performance of standard logistic regression with class weights. To do so, we use \"cross_val_score\" (http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html). This method takes as inputs the model we wish to fit, the features we will use as predictors, and the response variable. The output is an array of model performance scores. <p> \n",
    "    **Note** that the cross-validation used is a special kind known as **stratified** k-fold cross-validation. **Stratified** means that each fold maintains the proportion of M:B (1/0) cases as in the original data. \n",
    "    \n",
    "Read the scikit-learn website: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "Read \"field cv\":\n",
    "**For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. In all other cases, KFold is used.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:<font color=green> very very very important </font>:\n",
    "Be mindful that cross-validation is <font color=green>not</font> a way to build a model, it is only a<font color=green> method to evaluate</font> the performance of a given model in order to test or validation its generalization.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. Splitting the feature variables from the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We did this before, but we are going to do it again.\n",
    "\n",
    "X = dataframe.drop(axis=1, columns=['id', 'diagnosis'])\n",
    "y = dataframe['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "display(X[:][:5])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. Binarise the response:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we will use \"y_binary\" vector. Therefore, the classes in our dictionary will be 0 and 1 (instead of 'B' and 'M')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Checks:\n",
    "print('******************************************')\n",
    "#print(y)\n",
    "print('y - NO values =', sum(i =='B' for i in y))\n",
    "print('y - YES values =', sum(i =='M' for i in y))\n",
    "print('******************************************\\n')\n",
    "\n",
    "# Create y_binary\n",
    "y_binary = [0 if x=='B' else 1 for x in y]\n",
    "\n",
    "\n",
    "# Sanity Check\n",
    "print('A few elements of y: ', y[:12].ravel())\n",
    "print('Corresponding elements of y_binary: ', y_binary[:12])\n",
    "\n",
    "# Sanity Checks:\n",
    "print('\\n******************************************')\n",
    "#print(y)\n",
    "print('y_binary - 0 values =', sum(i ==0 for i in y_binary))\n",
    "print('y - 1 values =', sum(i ==1 for i in y_binary))\n",
    "print('******************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "print(y_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2. Cross-Validation + Pipelines:\n",
    "\n",
    "Recall that for regularization to be meaningful, we require the features to be <b>standardised</b>, and that we must fit the standardiser on the <b>*training set only*</b>, and then apply it to the test set. With cross-validation, the training and test set changes at each iteration. This means we must fit the scaler for each new training set in each iteration. We will achieve this by using a **pipeline**.<p> \n",
    "        **Pipelines** allow us to sequentially perform a list of transformations and a final estimator. In our case, we wish to apply the standardisation transformation, and then the logistic regression estimator.<p>\n",
    "            If we use a pipeline to make a cross-validated estimator using cross_val_score, then the StandardScaler will estimate the parameters for centering and rescaling to unit variance only on the training folds. When evaluating the pipeline on the test fold, the StandardScaler will use the stored means and standard deviations, and subtract the training mean from the test set and divide the result by the training standard deviation. So even in the pipeline, the StandardScaler will not use the test set in any way to determine mean and variance of the data.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read about Pipelines:\n",
    "1. https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "2. https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. Define our pipeline and then use cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default penalty is L2-norm (Ridge), but feel free to change to L1-norm (Lasso). In addition, feel free to change the value of  𝐶=𝑎𝑙𝑝ℎ𝑎 . If you wish to change these parameters, do it after you finish this exercise.\n",
    "\n",
    "Do you remember last week's assessment? We gave some weights associated with classes for readmission 'YES' and 'NO' in order to correct the imbalance in the data set. We can do the same here if we wish. I am going to the give the same value to the two classes, but feel free to experiment and change the values when you have finished this exercise: class_weight_dict={0:0.5, 1:0.5}. This is equivalent to give no weights. I just want to show you how to program it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler/Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "Scaler = StandardScaler()\n",
    "\n",
    "# Classification Model\n",
    "class_weight_dict={0:0.5, 1:0.5}\n",
    "Log_Reg = LogisticRegression(C = 0.5, penalty = 'l2', class_weight = class_weight_dict)\n",
    "\n",
    "# PipeLine\n",
    "pipe = Pipeline([('Transform', Scaler), ('Estimator', Log_Reg)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start using the function \"cross_val_score\", which is the scikit-learn function that Book 1 uses. We can read the API (application programming interface) here:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation (cross_val_score) + Pipeline, accuracy performance metric, and features with standardization (wst)\n",
    "# Be patient, it takes some time :-):\n",
    "\n",
    "from sklearn.model_selection import cross_val_score \n",
    "cv_acc_wst = cross_val_score(pipe, X, y_binary, cv = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "\n",
    "Check the field \"scoring\". As you can read, only a single metric is permitted.\n",
    "If this field is \"None\", the estimator’s default scorer (if available) is used.\n",
    "\n",
    "For LogisticRegression in scikit learn, the default scorer is \"accuracy\". Check the section \"methods\", the field \"score\":\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cross-validation accuracy scores:\\n {}\".format(cv_acc_wst))\n",
    "print(\"Average cross-validation score: {:.4f}\".format(cv_acc_wst.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the previous results (**cv_acc**), without standardization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Cross_validate + standardization\n",
    "\n",
    "Let's repeat the analysis using the function <font color=green>\"cross_validate\"</font> and \"standarization\". **The function <font color=green>\"cross_validate\"</font> allows us to use more than one metric at a time.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">**Start Activity**</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Question 4:  Write the function that calculates the 5-CV using \"cross_validate\"+ standardised features with Pipelines. Compute accuracy, recall, precision, auc and f1 scores.  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Python code here:\n",
    "\n",
    "# Scaler/Standardization\n",
    "\n",
    "# Classification Model\n",
    "\n",
    "# PipeLine\n",
    "\n",
    "# Scores: accuracy, recall, precision, f1 & roc_auc\n",
    "\n",
    "# cross_validate + Pipeline, all scores defined above, features with standardization (wst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Question 5:  Can we compare the current results against those without standardization?  </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Python code here:\n",
    "\n",
    "# Print accuracy for the k-folds and mean of the k-folds\n",
    "\n",
    "# Print recall for the k-folds and mean of the k-folds\n",
    "\n",
    "# Print precision for the k-folds and mean of the k-folds\n",
    "\n",
    "# Print f1 for the k-folds and mean of the k-folds\n",
    "\n",
    "# Print auc_roc for the k-folds and mean of the k-folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Write your answer here:</b>\n",
    "#####################################################################################################################\n",
    "\n",
    "(Double-click here)\n",
    "\n",
    "\n",
    "#####################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">**End Activity**</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
