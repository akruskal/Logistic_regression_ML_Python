{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/HDAT9500Banner.PNG)\n",
    "<br>\n",
    "\n",
    "# Chapter 3: Resampling Methods - Optional Exercise\n",
    "# Exercise 2: Bootstrapping (Over Sampling Majority Class)\n",
    "\n",
    "\n",
    "# 1. Introduction\n",
    "\n",
    "In this exercise, we will present a method to under-sample the majority class. The exercise is optional.\n",
    "\n",
    "\n",
    "## 1.1. Aims of the Exercise:\n",
    " 1. To become familiar with a method to under-sample the majority class\n",
    "\n",
    " \n",
    "It aligns with all the learning outcome of our course: \n",
    "\n",
    "1.\tDistinguish a range of task specific machine learning techniques appropriate for Health Data Science.\n",
    "2.\tDesign machine learning tasks for Health Data Science scenarios.\n",
    "3.\tConstruct appropriate training and test sets for health research data.\n",
    "\n",
    "\n",
    "\n",
    "## 1.2. Jupyter Notebook Intructions\n",
    "1. Read the content of each cell.\n",
    "2. Where necessary, follow the instructions that are written in each cell.\n",
    "3. Run/Execute all the cells that contain Python code sequentially (one at a time), using the \"Run\" button.\n",
    "4. For those cells in which you are asked to write some code, please write the Python code first and then execute/run the cell.\n",
    " \n",
    "## 1.3. Tips\n",
    " 1. The square brackets on the left hand side of each cell indicate whether the cell has been executed or not. Empty square brackets mean that the cell has not been excuted, whereas square brackets that contain a number means that the cell has been executed. Run all the cells in sequence, using the \"Run\" button.\n",
    " 2. To edit this notebook, just double-click in each cell. In thid document, each cell can be a \"Code\" cell or \"text-Markdown\" cell. To choose between these two options, go to the combo-box above. \n",
    " 3. If you want to save your notebook, please make sure you press \"the floppy disk\" icon button above. \n",
    " 4. To clean the content of all cells and re-start Notebook, please go to Cell->All Output->Clear\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load the standardized training and test data, and the hospital data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "#For this notebook to work, Python must be 3.6.4 or 3.6.5\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital = pd.read_csv('data/diabetes/Data_Class_Dummies.csv', sep=',')\n",
    "train_standardized_data = pd.read_csv('data/diabetes/train_standardized_data.csv', sep=',')\n",
    "test_standardized_data = pd.read_csv('data/diabetes/test_standardized_data.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Split the training and test data into features and response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_standardized = train_standardized_data.drop(['readmission'], axis = 1)\n",
    "y_train = train_standardized_data[['readmission']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_standardized = test_standardized_data.drop(['readmission'], axis = 1)\n",
    "y_test = test_standardized_data[['readmission']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_standardized.shape)\n",
    "print(X_test_standardized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Binarise response\n",
    "We will be using the f1 score at various points in this exercise. So, lets create a binary response for the training and test response vectors we have created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Training response:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Checks:\n",
    "print('******************************************')\n",
    "#print(y_train)\n",
    "print('y_train - NO values =', sum(i =='NO' for i in y_train))\n",
    "print('y_train - YES values =', sum(i =='YES' for i in y_train))\n",
    "print('******************************************\\n')\n",
    "\n",
    "# Create y_train_binary\n",
    "y_train_binary = [0 if x=='NO' else 1 for x in y_train]\n",
    "\n",
    "\n",
    "# Sanity Check\n",
    "print('A few elements of y_train: ', y_train[:12].ravel())\n",
    "print('Corresponding elements of y_train_binary: ', y_train_binary[:12])\n",
    "\n",
    "# Sanity Checks:\n",
    "print('\\n******************************************')\n",
    "#print(y_train)\n",
    "print('y_train_binary - 0 values =', sum(i ==0 for i in y_train_binary))\n",
    "print('y_train - 1 values =', sum(i ==1 for i in y_train_binary))\n",
    "print('******************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Test response:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Checks:\n",
    "print('******************************************')\n",
    "#print(y_test)\n",
    "print('y_test - NO values =', sum(i =='NO' for i in y_test))\n",
    "print('y_test - YES values =', sum(i =='YES' for i in y_test))\n",
    "print('******************************************\\n')\n",
    "\n",
    "# Create y_test_binary\n",
    "y_test_binary = [0 if x=='NO' else 1 for x in y_test]\n",
    "\n",
    "\n",
    "# Sanity Check\n",
    "print('A few elements of y_test: ', y_test[:12].ravel())\n",
    "print('Corresponding elements of y_test_binary: ', y_test_binary[:12])\n",
    "\n",
    "# Sanity Checks:\n",
    "print('\\n******************************************')\n",
    "#print(y_test)\n",
    "print('y_test_binary - 0 values =', sum(i ==0 for i in y_test_binary))\n",
    "print('y_test - 1 values =', sum(i ==1 for i in y_test_binary))\n",
    "print('******************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Under sampling majority class, readmission = NO.\n",
    "Recall from Chapter 3 Exercise 1 that we used the SMOTE algorithm to make the class value counts equal. Now, we will over sample the majority class. As before, the goal is to rebalance the proportion of class labels. Now, rather than create new data points from the minority class, we will remove points from the majority class.<p>\n",
    "    A naive approach would be to remove the points randomly. However, we can choose to remove the points that make prediction difficult. These points are those that are very close to points of the opposite class. A useful notion is *Tomek Links*. These are points (A,B) such that A and B are each others closest neighbour, and have opposing class labels. Please see [this website](https://blog.dominodatalab.com/imbalanced-datasets/) for a nice explanation of how the method works.<p> \n",
    "        ![alt text](https://raw.githubusercontent.com/rafjaa/machine_learning_fecib/master/src/static/img/tomek.png?v=2 \"Tomek Links Visualisation\")<p>\n",
    "        It is the NO half of these *Tomek Links* that we will remove.<p>\n",
    "            **Note**: In the case of the SMOTE algorithm, we over sample the majority class in order to make the ratio of NO to YES *exactly equal*. For this under sampling algorithm, we only remove the NO records *that are Tomek links*, and no further records. This means that the ratios will not be equal.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](http://contrib.scikit-learn.org/imbalanced-learn/stable/_images/sphx_glr_plot_tomek_links_001.png \"Tomek Links Visualisation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Deleting points of class label NO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: TomekLinks method is computationally expensive, as at each step we need to compute the distances between every point in the data set. Please allow ~10 minutes for the process to finish.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tLinks = TomekLinks(return_indices = False)\n",
    "X_train_standardized_tl, y_train_tl = tLinks.fit_sample(X_train_standardized, y_train_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_standardized_data['readmission'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For even ratio, need to remove the following number of records from the NO class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_standardized_data['readmission'].value_counts()[0]-train_standardized_data['readmission'].value_counts()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of NO class records actually removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_standardized_data['readmission'].value_counts()[0] - np.unique(y_train_tl, return_counts = True)[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm says that no YES class records are removed. Lets check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_standardized_data['readmission'].value_counts()[1] - np.unique(y_train_tl, return_counts = True)[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(y_train_tl, return_counts = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Train logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Log_Reg = LogisticRegression(C = 1/20, penalty = 'l1').fit(X_train_standardized_tl, y_train_tl.ravel()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\beta$ Coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.round(Log_Reg.coef_, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model predictions on test set\n",
    "y_pred= Log_Reg.predict(X_test_standardized)\n",
    "\n",
    "# Use score method to get accuracy of model\n",
    "score = Log_Reg.score(X_test_standardized, y_test_binary)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true = y_test_binary, y_pred = y_pred)\n",
    "print(\"Confusion matrix:\\n{}\".format(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tomek link method did not perform very well in this case. This could be due to the fact that only a small portion of NO records were removed, so that the class imbalance issue is still a major problem for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Evaluating the model using unweighted mean of F1 Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(y_true = y_test_binary, y_pred = y_pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Receiver Operating Characteristic (ROC): TPR and FPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1. Probability associated with each prediction\n",
    "We need to determine the probability of each record in the test set being a 'YES', or equivalently a 1 as we have converted the response into a binary variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilities of the test set being 0 and 1\n",
    "y_pred_proba = Log_Reg.predict_proba(X_test_standardized)[:,1]\n",
    "y_pred\n",
    "\n",
    "print(y_pred_proba[:5])\n",
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2. Determining the fpr, tpr at each threshold value\n",
    "Now that we have the probabilitys associated with each prediction, we know exactly which records are predicted YES and NO for each choice of decision threshold. Hence, we can determine the false positive rate (fpr) and true positive rate (tpr) for threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test_binary, y_pred_proba)\n",
    "print(fpr[:4])\n",
    "print(tpr[:4])\n",
    "print(thresholds[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3. Plotting The ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['fpr'] = fpr\n",
    "df['tpr'] = tpr\n",
    "# Sanity check \n",
    "display(df[:][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr,_= metrics.roc_curve(y_true = y_test_binary, y_score = y_pred_proba)\n",
    "\n",
    "from plotnine import *\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "p = ggplot(mapping = aes(x = fpr, y = tpr), data = df)\n",
    "p += geom_line(color = 'red')\n",
    "p += geom_abline(aes(intercept=0, slope=1), linetype = 'dashed', colour = 'blue')\n",
    "p += labs(title = 'ROC Curve', x = 'fpr', y = 'tpr')\n",
    "p += theme_bw()\n",
    "\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.4. Area under the ROC curve (AUC)\n",
    "Note that AUC = 0.5 corresponds to random assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.roc_auc_score(y_true = y_test_binary, y_score = y_pred_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Computing optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index of pair that maximises tpr - fpr\n",
    "ind_max = np.argmax(tpr - fpr)\n",
    "print(ind_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold value that maximises the tpr - fpr\n",
    "optimal_thresh = thresholds[ind_max]\n",
    "print(optimal_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Using Tomek Links AND SMOTE\n",
    "Recall that SMOTE synthetically generates minority class records whilst avoiding duplications. Here, we will use this method after we have removed all the Tomek Link majority records. Our hope is that the removal of Tomek Links will complement the SMOTE method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(k_neighbors = 5, ratio = 'minority', random_state = 0, kind = \"regular\")\n",
    "X_train_standardized_tl_smote, y_train_tl_smote = smote.fit_sample(X_train_standardized_tl, y_train_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train_tl_smote, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Log_Reg = LogisticRegression(C = 1/20, penalty = 'l1').fit(X_train_standardized_tl_smote, y_train_tl_smote.ravel()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(Log_Reg.coef_, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions \n",
    "y_pred= Log_Reg.predict(X_test_standardized)\n",
    "\n",
    "# Use score method to get accuracy of model\n",
    "score = Log_Reg.score(X_test_standardized, y_test_binary)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true = y_test_binary, y_pred = y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of YES\n",
    "acc_pos = cm[1][1]/(cm[1][1] + cm[0][1])\n",
    "print(acc_pos)\n",
    "\n",
    "# Accuracy of NO\n",
    "acc_neg = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(acc_neg)\n",
    "\n",
    "# Balanced Accuracy\n",
    "BACC = (acc_pos + acc_neg)/2\n",
    "print(BACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(y_true = y_test_binary, y_pred = y_pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is only a small improvement to the SMOTE results individually, suggesting that removing the Tomek Links does not influence the prediction problem a great deal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">**Start Activity 1**</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Question 1: Describe the steps that we follow in this exercise </font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Write your answer here:</b>\n",
    "#####################################################################################################################\n",
    "\n",
    "(Double-click here)\n",
    "\n",
    "\n",
    "#####################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">**End Activity 1**</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
